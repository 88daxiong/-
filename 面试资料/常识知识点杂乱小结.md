# 常识知识点杂乱小结

后续会将此小结的点放到对应的框架上，此小姐仅记录日常遇到的小知识点。



*先验概率:是指根据以往经验和分析得到的概率*，**我们人在未知条件下对事件发生可能性猜测的数学表示**!

*后验概率:**事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小***。（果因概率，即产生的这个结果是由于这个因产生的概率有多大）

$P(A/B) = \frac{P(B/A)*P(A)}{P(B)}$

这里：

> 后验概率是$P(A/B)$，意思是现在B已经发生了，而发生B这件事是由A引起的概率有多大。
>
> 先验概率是$P(A)$，这里A发生的概率是我们猜测的，是由经验得到的。比如掷骰子，1出现的概率是1/6。
>
> 类条件概率$P(B/A)$，表示每种概率的分布概率

这里给出一个比较形象的公式：

$P(原因1/结果) = \frac{P(原因1导致结果)}{P(结果)} =\frac{P(结果/原因1)*(P(原因1))}{P(结果)}$

假设产生这个结果只有K个可能的原因，那么，结果的概率又可以写为：

$P(结果) = P(结果/原因1)*P(原因1) + P(结果/原因2)*P(原因2) + ... +P(结果/原因k)*P(原因k)$

这里，$P(原因1/结果) $为后验概率，$P(原因1)$为先验概率。

**"概率论只不过是把常识用数学公式表达了出来"---拉普拉斯**



误差（Error）：**预测结果和真实结果之间的差值**。

偏差（Bias）：在**训练集上的误差叫做偏差**，也就是评估模型在训练集上的表现。

方差（Variance）：**训练集和测试集上的差异叫方差**，也就是评估模型训练好之后，在测试集上的表现。

过拟合（Overfitting）：在训练集上效果特别好，在测试集上效果不好；也就是低偏差，高方差。也就是泛化能力差。

欠拟合（Underfitting）：在训练集和测试集上效果都不好；也就是高偏差，低方差。也就是拟合数据的能力差。

过拟合解决办法：设计更加简单的模型、增加模型的训练数据、正则化（损失函数后面加L2等）、使用Dropout层（随机使神经元失效）、调整超参数、提前结束训练、尝试其它模型等；

欠拟合解决办法：增加模型的训练数据、增加模型的深度和复杂度、增加迭代次数、更好的优化函数、调整超参数。



训练集：相当于平时的学习，可以不断的学习新的知识。训练集在我们模型的过程中起的作用就是**更新模型的参数**，用以获得更好的性能，其行为表现就是让我们以为模型掌握了相关的知识（规律）

验证集：相当于模拟考试，可以继续巩固学习的知识，是否是**学习到的和真实的有偏差**。验证集就是为了**调整我们模型的超参数（神经元的数量、迭代的次数、序列长度等等）**，这些超参数在某一次的学习迭代中是没有办法改变的。

测试集：相当于高考，这时候已经不能再学习和巩固，只能得到**最终的学习结果和真实结果的差异值**。不会有反馈，最终评价模型效果的集合。









