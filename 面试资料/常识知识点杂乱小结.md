# 常识知识点杂乱小结

后续会将此小结的点放到对应的框架上，此小姐仅记录日常遇到的小知识点。



*先验概率:是指根据以往经验和分析得到的概率*，**我们人在未知条件下对事件发生可能性猜测的数学表示**!

*后验概率:**事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小***。（果因概率，即产生的这个结果是由于这个因产生的概率有多大）

$P(A/B) = \frac{P(B/A)*P(A)}{P(B)}$

这里：

> 后验概率是$P(A/B)$，意思是现在B已经发生了，而发生B这件事是由A引起的概率有多大。
>
> 先验概率是$P(A)$，这里A发生的概率是我们猜测的，是由经验得到的。比如掷骰子，1出现的概率是1/6。
>
> 类条件概率$P(B/A)$，表示每种概率的分布概率

这里给出一个比较形象的公式：

$P(原因1/结果) = \frac{P(原因1导致结果)}{P(结果)} =\frac{P(结果/原因1)*(P(原因1))}{P(结果)}$

假设产生这个结果只有K个可能的原因，那么，结果的概率又可以写为：

$P(结果) = P(结果/原因1)*P(原因1) + P(结果/原因2)*P(原因2) + ... +P(结果/原因k)*P(原因k)$

这里，$P(原因1/结果) $为后验概率，$P(原因1)$为先验概率。

**"概率论只不过是把常识用数学公式表达了出来"---拉普拉斯**



误差（Error）：**预测结果和真实结果之间的差值**。

偏差（Bias）：在**训练集上的误差叫做偏差**，也就是评估模型在训练集上的表现。

方差（Variance）：**训练集和测试集上的差异叫方差**，也就是评估模型训练好之后，在测试集上的表现。

过拟合（Overfitting）：在训练集上效果特别好，在测试集上效果不好；也就是低偏差，高方差。也就是泛化能力差。

欠拟合（Underfitting）：在训练集和测试集上效果都不好；也就是高偏差，低方差。也就是拟合数据的能力差。

过拟合解决办法：设计更加简单的模型、增加模型的训练数据、正则化（损失函数后面加L2等）、使用Dropout层（随机使神经元失效）、调整超参数、提前结束训练、尝试其它模型等；

欠拟合解决办法：增加模型的训练数据、增加模型的深度和复杂度、增加迭代次数、更好的优化函数、调整超参数。



训练集：相当于平时的学习，可以不断的学习新的知识。训练集在我们模型的过程中起的作用就是**更新模型的参数**，用以获得更好的性能，其行为表现就是让我们以为模型掌握了相关的知识（规律）

验证集：相当于模拟考试，可以继续巩固学习的知识，是否是**学习到的和真实的有偏差**。验证集就是为了**调整我们模型的超参数（神经元的数量、迭代的次数、序列长度等等）**，这些超参数在某一次的学习迭代中是没有办法改变的。

测试集：相当于高考，这时候已经不能再学习和巩固，只能得到**最终的学习结果和真实结果的差异值**。不会有反馈，最终评价模型效果的集合。



感知机可以理解为单层的神经网络
多层的神经网络叫做深度学习
决策树解决的是无非线性因素的分类
随机森林是多决策树
KNN是用最小距离法做聚类的
贝叶斯是根据先验概率去做统计的算法
马尔可夫可以理解为多个贝叶斯概率串起来解决状态转移的概率
支持向量机是利用线性算法去拟合分割平面的分类算法
逻辑回归解决的是连续型拟合（分类相当于离散型）
梯度下降并不是机器学习的算法，而是神经网络的反向传播算法，用来调整权重参数
最小二乘法也是类似的，它也是一种参数估计的算法
深度学习即可做生成（升维，解码），也可以做判别（或者叫分类，降维，编码）



[回归与分类的区别](https://www.cnblogs.com/aurorablog/p/9034491.html)

1）输出数据的类型

分类输出的数据类型是离散数据，也就是分类的标签。比如我们前面通过学生学习预测考试是否通过，这里的预测结果是考试通过，或者不通过，这2种离散数据。

回归输出的是连续数据类型。比如我们通过学习时间预测学生的考试分数，这里的预测结果分数，是连续数据。

2）第2个区别是我们想要通过机器学习算法得到什么？

分类算法得到是一个决策面，用于对数据集中的数据进行分类。

回归算法得到是一个最优拟合线，这个线条可以最好的接近数据集中的各个点。

3）第3个区别是对模型的评估指标不一样

在监督分类中，我们我们通常会使用正确率作为为指标，也就是预测结果中分类正确数据占总数据的比例

在回归中，我们用决定系数R平方来评估模型的好坏。R平方表示有多少百分比的y波动被回归线描述。





